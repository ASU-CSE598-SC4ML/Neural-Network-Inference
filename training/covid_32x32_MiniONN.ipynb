{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a6ea6a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "parliamentary-election",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-13T20:41:32.890680Z",
     "start_time": "2021-04-13T20:41:32.035056Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "from os import listdir, makedirs, getcwd, remove\n",
    "from os.path import isfile, join, abspath, exists, isdir, expanduser\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.autograd as autograd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.utils.data as data\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import itertools\n",
    "\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets, models\n",
    "from torch import Tensor\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "from resnet import resnet32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "varied-montana",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-13T20:41:32.977685Z",
     "start_time": "2021-04-13T20:41:32.972006Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class medical_dataset(Dataset):\n",
    "    def __init__(self, covid_path, normal_path, transform=None):\n",
    "        self.covid_path = covid_path\n",
    "        self.normal_path = normal_path\n",
    "\n",
    "        self.transform = transforms.Compose([\n",
    "            lambda x: Image.open(x).convert('RGB'),\n",
    "            transforms.Resize((32, 32)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "        ])\n",
    "\n",
    "        self.covid_img = listdir(self.covid_path)\n",
    "        self.normal_img = listdir(self.normal_path)\n",
    "        \n",
    "        print(\"Class imbalance is: {}\".format(len(self.normal_img)/len(self.covid_img)))\n",
    "        \n",
    "        self.indices=np.arange(len(self.covid_img)+len(self.normal_img))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.normal_img) + len(self.covid_img)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        if (idx + 1 <= len(self.normal_img)):\n",
    "            img = self.transform(join(self.normal_path, self.normal_img[idx]))\n",
    "            label = 0\n",
    "        else:\n",
    "            idx = idx - len(self.normal_img)\n",
    "            img = self.transform(join(self.covid_path, self.covid_img[idx]))\n",
    "            label = 1\n",
    "\n",
    "        return img, torch.tensor([label]).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56e92dee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-13T20:41:33.078484Z",
     "start_time": "2021-04-13T20:41:33.067570Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class imbalance is: 2.8185840707964602\n"
     ]
    }
   ],
   "source": [
    "dataset = medical_dataset(\n",
    "    covid_path='./dataset/archive/COVID-19_Radiography_Dataset/COVID/',\n",
    "    normal_path='./dataset/archive/COVID-19_Radiography_Dataset/Normal/',\n",
    ")\n",
    "\n",
    "X_unshuffled = dataset.indices\n",
    "rs = ShuffleSplit(n_splits=1, test_size=.2, random_state=32)\n",
    "rs.get_n_splits(X_unshuffled)\n",
    "\n",
    "train_ind = []\n",
    "val_ind = []\n",
    "for train_index, test_index in rs.split(X_unshuffled):\n",
    "    train_ind.append(train_index)\n",
    "    val_ind.append(test_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d9ea4797",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-13T20:41:37.734151Z",
     "start_time": "2021-04-13T20:41:37.725129Z"
    }
   },
   "outputs": [],
   "source": [
    "train_sampler = SubsetRandomSampler(train_ind[0].tolist())\n",
    "test_sampler = SubsetRandomSampler(val_ind[0].tolist())\n",
    "\n",
    "train_loader = DataLoader(dataset, batch_size=32, sampler=train_sampler)\n",
    "test_loader = DataLoader(dataset, batch_size=32, sampler=test_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "14495059",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-13T20:43:01.343076Z",
     "start_time": "2021-04-13T20:42:58.542745Z"
    }
   },
   "outputs": [],
   "source": [
    "class MiniONN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 64, 3, 1, 1)\n",
    "        self.conv2 = nn.Conv2d(64, 64, 3, 1, 1)\n",
    "        self.conv3 = nn.Conv2d(64, 64, 3, 1, 1)\n",
    "        self.conv4 = nn.Conv2d(64, 64, 3, 1, 1)\n",
    "        self.conv5 = nn.Conv2d(64, 64, 3, 1, 1)\n",
    "        \n",
    "        self.conv6 = nn.Conv2d(64, 64, 1, 1, 0)\n",
    "        self.conv7 = nn.Conv2d(64, 16, 1, 1, 0)\n",
    "        \n",
    "        self.fc = nn.Linear(1024, 1)\n",
    "        \n",
    "        self.avg1 = nn.AvgPool2d(2, 2)\n",
    "        self.avg2 = nn.AvgPool2d(2, 2)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        h = F.relu(self.conv1(x))\n",
    "        h = F.relu(self.conv2(h))\n",
    "        \n",
    "        h = self.avg1(h)\n",
    "        \n",
    "        h = F.relu(self.conv3(h))\n",
    "        h = F.relu(self.conv4(h))\n",
    "        \n",
    "        h = self.avg2(h)\n",
    "        \n",
    "        h = F.relu(self.conv5(h))\n",
    "        h = F.relu(self.conv6(h))\n",
    "        h = F.relu(self.conv7(h))\n",
    "        \n",
    "        h = h.view(-1, 1024)\n",
    "        h = self.fc(h)\n",
    "        \n",
    "        return h\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4e974ca0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-13T20:43:06.282420Z",
     "start_time": "2021-04-13T20:43:06.280186Z"
    }
   },
   "outputs": [],
   "source": [
    "model_ft = MiniONN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a4ff8f59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_ft.load_state_dict(torch.load(\"./models/minionn/checkpoint.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ee5902a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model_ft.cpu(), \"./models/minionn/checkpoint_cpu_cpu.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a9f11011",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-13T20:43:15.128268Z",
     "start_time": "2021-04-13T20:43:15.109819Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n",
    "    def __init__(self,\n",
    "                 patience=7,\n",
    "                 verbose=False,\n",
    "                 delta=0,\n",
    "                 path='./models/minionn/checkpoint.pt',\n",
    "                 trace_func=print):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            patience (int): How long to wait after last time validation loss improved.\n",
    "                            Default: 7\n",
    "            verbose (bool): If True, prints a message for each validation loss improvement. \n",
    "                            Default: False\n",
    "            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
    "                            Default: 0\n",
    "            path (str): Path for the checkpoint to be saved to.\n",
    "                            Default: 'checkpoint.pt'\n",
    "            trace_func (function): trace print function.\n",
    "                            Default: print            \n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.Inf\n",
    "        self.delta = delta\n",
    "        self.path = path\n",
    "        self.trace_func = trace_func\n",
    "\n",
    "    def __call__(self, val_loss, model):\n",
    "\n",
    "        score = -val_loss\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            self.trace_func(\n",
    "                f'EarlyStopping counter: {self.counter} out of {self.patience}'\n",
    "            )\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model):\n",
    "        '''Saves model when validation loss decrease.'''\n",
    "        if self.verbose:\n",
    "            self.trace_func(\n",
    "                f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...'\n",
    "            )\n",
    "        torch.save(model.state_dict(), self.path)\n",
    "        self.val_loss_min = val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "030c1067",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-13T00:50:43.428807Z",
     "start_time": "2021-04-13T00:50:43.412396Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "\n",
    "class Trainer:\n",
    "    def __init__(self,\n",
    "                 trainloader,\n",
    "                 vallaoder,\n",
    "                 model_ft,\n",
    "                 writer=None,\n",
    "                 testloader=None,\n",
    "                 checkpoint_path=None,\n",
    "                 patience=5,\n",
    "                 feature_extract=True,\n",
    "                 print_itr=50):\n",
    "        self.trainloader = trainloader\n",
    "        self.valloader = vallaoder\n",
    "        self.testloader = testloader\n",
    "\n",
    "#         self.device = torch.device(\n",
    "#             \"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "        self.device = torch.device(\"cpu\")\n",
    "\n",
    "        print(\"==\" * 10)\n",
    "        print(\"Training will be done on \", self.device)\n",
    "        print(\"==\" * 10)\n",
    "\n",
    "        self.model = model_ft\n",
    "        self.model = self.model.to(self.device)\n",
    "\n",
    "        # Observe that all parameters are being optimized\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=0.0001)\n",
    "        self.criterion = nn.BCELoss()\n",
    "\n",
    "        self.early_stopping = EarlyStopping(patience=patience, verbose=True)\n",
    "        self.writer = writer\n",
    "        self.print_itr = print_itr\n",
    "\n",
    "    def train(self, ep):\n",
    "        self.model.train()\n",
    "\n",
    "        running_loss = 0.0\n",
    "        train_tqdm = tqdm(self.trainloader)\n",
    "\n",
    "        for en, (x, y) in enumerate(train_tqdm):\n",
    "            x = x.to(self.device)\n",
    "            y = y.to(self.device)\n",
    "\n",
    "            self.optimizer.zero_grad()\n",
    "\n",
    "            outputs = F.sigmoid(self.model(x))\n",
    "            loss = self.criterion(outputs, y)\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            train_tqdm.set_description(\"Loss: {}\".format(running_loss))\n",
    "            running_loss = 0\n",
    "\n",
    "            # print statistics\n",
    "\n",
    "\n",
    "#             running_loss += loss.item()\n",
    "#             if (en + 1) % self.print_itr == 0:\n",
    "#                 print('[%d, %5d] loss: %.3f' %\n",
    "#                       (ep, en + 1, running_loss / self.print_itr))\n",
    "#                 running_loss = 0.0\n",
    "\n",
    "    def validate(self, ep):\n",
    "        self.model.eval()\n",
    "\n",
    "        total = 0\n",
    "        correct = 0\n",
    "        running_loss = 0.0\n",
    "        for en, (x, y) in enumerate(tqdm(self.valloader)):\n",
    "\n",
    "            x = x.to(self.device)\n",
    "            y = y.to(self.device)\n",
    "\n",
    "            outputs = F.sigmoid(self.model(x))\n",
    "            loss = self.criterion(outputs, y)\n",
    "\n",
    "            predicted = torch.tensor([1 if outputs[i]>=0.5 else 0 for i in range(outputs.shape[0])])\n",
    "\n",
    "            total += y.size(0)\n",
    "            correct += (predicted.squeeze() == y.cpu().squeeze()).sum().item()\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "        return running_loss / len(self.valloader), correct * 100 / total\n",
    "\n",
    "    def evaluate(self, ep, dataloader):\n",
    "        self.model.eval()\n",
    "\n",
    "        total = 0\n",
    "        correct = 0\n",
    "        for en, (x, y) in enumerate(tqdm(dataloader)):\n",
    "\n",
    "            x = x.to(self.device)\n",
    "            y = y.to(self.device)\n",
    "\n",
    "            outputs = F.sigmoid(self.model(x))\n",
    "            predicted = torch.tensor([1 if outputs[i]>=0.5 else 0 for i in range(outputs.shape[0])])\n",
    "#             print(predicted.shape)\n",
    "            total += y.size(0)\n",
    "            correct += (predicted.squeeze() == y.cpu().squeeze()).sum().item()\n",
    "\n",
    "        return correct * 100 / total\n",
    "\n",
    "    def perform_training(self, total_epoch):\n",
    "        val_loss, acc = self.validate(0)\n",
    "\n",
    "        print(\"[Initial Validation results] Loss: {} \\t Acc:{}\".format(\n",
    "            val_loss, acc))\n",
    "\n",
    "        for i in range(total_epoch):\n",
    "            self.train(i + 1)\n",
    "            val_loss, acc = self.validate(i + 1)\n",
    "            #             acc = self.evaluate(i+1, self.valloader)\n",
    "            print(\"Epoch:{} \\t Accuracy:{}\".format(i+1, acc))\n",
    "            if self.writer:\n",
    "                self.writer.add_scalar('Validation Loss', val_loss, (i + 1))\n",
    "                self.writer.add_scalar('Validation Acc', acc, (i + 1))\n",
    "\n",
    "            self.early_stopping(val_loss, self.model)\n",
    "\n",
    "            if self.early_stopping.early_stop:\n",
    "                print(\"Early stopping\")\n",
    "                break\n",
    "\n",
    "        print(\"=\" * 20)\n",
    "        print(\"Training finished !!\")\n",
    "        print(\"=\" * 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "90e8035d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-13T00:50:45.384597Z",
     "start_time": "2021-04-13T00:50:43.430311Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================\n",
      "Training will be done on  cpu\n",
      "====================\n"
     ]
    }
   ],
   "source": [
    "writer = SummaryWriter('runs/minionn')\n",
    "trainer = Trainer(train_loader, test_loader, model_ft, writer=writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bd03b03d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-13T02:00:55.680239Z",
     "start_time": "2021-04-13T00:50:45.385992Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/87 [00:00<?, ?it/s]/home/maitreya/Courses/SCML/COVID/env/lib/python3.8/site-packages/torch/nn/functional.py:1709: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "100%|██████████| 87/87 [00:04<00:00, 19.45it/s]\n",
      "Loss: 0.682716429233551:   0%|          | 1/346 [00:00<00:54,  6.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Initial Validation results] Loss: 0.6851303200612123 \t Acc:74.04055032585083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.5923810005187988: 100%|██████████| 346/346 [00:26<00:00, 13.10it/s] \n",
      "100%|██████████| 87/87 [00:04<00:00, 19.86it/s]\n",
      "Loss: 0.7306787967681885:   1%|          | 2/346 [00:00<00:25, 13.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:1 \t Accuracy:75.74221578566257\n",
      "Validation loss decreased (inf --> 0.477536).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.8527958393096924: 100%|██████████| 346/346 [00:22<00:00, 15.06it/s] \n",
      "100%|██████████| 87/87 [00:04<00:00, 19.85it/s]\n",
      "Loss: 0.6016228199005127:   1%|          | 2/346 [00:00<00:23, 14.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:2 \t Accuracy:83.20057929036929\n",
      "Validation loss decreased (0.477536 --> 0.385155).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.31926199793815613: 100%|██████████| 346/346 [00:22<00:00, 15.06it/s]\n",
      "100%|██████████| 87/87 [00:04<00:00, 19.90it/s]\n",
      "Loss: 0.29629406332969666:   1%|          | 2/346 [00:00<00:23, 14.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:3 \t Accuracy:86.42288196958725\n",
      "Validation loss decreased (0.385155 --> 0.328742).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.1743118017911911: 100%|██████████| 346/346 [00:22<00:00, 15.10it/s] \n",
      "100%|██████████| 87/87 [00:04<00:00, 19.91it/s]\n",
      "Loss: 0.3928096294403076:   1%|          | 2/346 [00:00<00:24, 14.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:4 \t Accuracy:86.13323678493845\n",
      "EarlyStopping counter: 1 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.6721366047859192: 100%|██████████| 346/346 [00:23<00:00, 14.85it/s] \n",
      "100%|██████████| 87/87 [00:04<00:00, 20.07it/s]\n",
      "Loss: 0.2701786756515503:   1%|          | 2/346 [00:00<00:24, 14.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:5 \t Accuracy:87.21940622737146\n",
      "Validation loss decreased (0.328742 --> 0.286246).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.22350013256072998: 100%|██████████| 346/346 [00:23<00:00, 14.80it/s]\n",
      "100%|██████████| 87/87 [00:04<00:00, 19.87it/s]\n",
      "Loss: 0.5423309803009033:   1%|          | 2/346 [00:00<00:25, 13.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:6 \t Accuracy:87.69007965242578\n",
      "Validation loss decreased (0.286246 --> 0.281410).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.1103893518447876: 100%|██████████| 346/346 [00:23<00:00, 14.65it/s] \n",
      "100%|██████████| 87/87 [00:04<00:00, 19.88it/s]\n",
      "Loss: 0.3503119647502899:   1%|          | 2/346 [00:00<00:25, 13.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:7 \t Accuracy:89.10209992758871\n",
      "Validation loss decreased (0.281410 --> 0.274759).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.22305792570114136: 100%|██████████| 346/346 [00:23<00:00, 14.69it/s]\n",
      "100%|██████████| 87/87 [00:04<00:00, 19.78it/s]\n",
      "Loss: 0.24596792459487915:   1%|          | 2/346 [00:00<00:24, 13.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:8 \t Accuracy:88.95727733526431\n",
      "Validation loss decreased (0.274759 --> 0.267993).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.03144235908985138: 100%|██████████| 346/346 [00:23<00:00, 14.51it/s]\n",
      "100%|██████████| 87/87 [00:04<00:00, 19.57it/s]\n",
      "Loss: 0.26645973324775696:   1%|          | 2/346 [00:00<00:24, 14.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:9 \t Accuracy:88.7762490948588\n",
      "EarlyStopping counter: 1 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3038310408592224: 100%|██████████| 346/346 [00:23<00:00, 14.70it/s]  \n",
      "100%|██████████| 87/87 [00:04<00:00, 20.18it/s]\n",
      "Loss: 0.07431577891111374:   0%|          | 1/346 [00:00<00:40,  8.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10 \t Accuracy:89.46415640839972\n",
      "Validation loss decreased (0.267993 --> 0.253791).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.10680681467056274: 100%|██████████| 346/346 [00:23<00:00, 14.91it/s]\n",
      "100%|██████████| 87/87 [00:04<00:00, 19.70it/s]\n",
      "Loss: 0.24118764698505402:   1%|          | 2/346 [00:00<00:24, 13.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:11 \t Accuracy:89.64518464880521\n",
      "EarlyStopping counter: 1 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.37095174193382263: 100%|██████████| 346/346 [00:23<00:00, 14.86it/s]\n",
      "100%|██████████| 87/87 [00:04<00:00, 19.85it/s]\n",
      "Loss: 0.17621935904026031:   1%|          | 2/346 [00:00<00:24, 14.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:12 \t Accuracy:90.07965242577842\n",
      "EarlyStopping counter: 2 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.19959914684295654: 100%|██████████| 346/346 [00:23<00:00, 14.72it/s]\n",
      "100%|██████████| 87/87 [00:04<00:00, 19.30it/s]\n",
      "Loss: 0.26152029633522034:   1%|          | 2/346 [00:00<00:25, 13.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:13 \t Accuracy:88.74004344677769\n",
      "EarlyStopping counter: 3 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.13465173542499542: 100%|██████████| 346/346 [00:23<00:00, 14.61it/s]\n",
      "100%|██████████| 87/87 [00:04<00:00, 20.04it/s]\n",
      "Loss: 0.28691455721855164:   1%|          | 2/346 [00:00<00:25, 13.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:14 \t Accuracy:89.82621288921072\n",
      "Validation loss decreased (0.253791 --> 0.248801).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.07968512922525406: 100%|██████████| 346/346 [00:23<00:00, 14.42it/s]\n",
      "100%|██████████| 87/87 [00:04<00:00, 20.13it/s]\n",
      "Loss: 0.22770081460475922:   1%|          | 2/346 [00:00<00:25, 13.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:15 \t Accuracy:90.11585807385953\n",
      "Validation loss decreased (0.248801 --> 0.242016).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.4892733097076416: 100%|██████████| 346/346 [00:24<00:00, 14.25it/s] \n",
      "100%|██████████| 87/87 [00:04<00:00, 20.03it/s]\n",
      "Loss: 0.2366361767053604:   1%|          | 2/346 [00:00<00:24, 13.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:16 \t Accuracy:90.26068066618393\n",
      "Validation loss decreased (0.242016 --> 0.241898).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.08033476024866104: 100%|██████████| 346/346 [00:23<00:00, 14.49it/s] \n",
      "100%|██████████| 87/87 [00:04<00:00, 20.15it/s]\n",
      "Loss: 0.2778118848800659:   0%|          | 1/346 [00:00<00:41,  8.22it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:17 \t Accuracy:90.18826937002173\n",
      "Validation loss decreased (0.241898 --> 0.236457).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.010079403407871723: 100%|██████████| 346/346 [00:24<00:00, 14.36it/s]\n",
      "100%|██████████| 87/87 [00:04<00:00, 19.28it/s]\n",
      "Loss: 0.10027806460857391:   1%|          | 2/346 [00:00<00:25, 13.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:18 \t Accuracy:89.42795076031861\n",
      "EarlyStopping counter: 1 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.01889205537736416: 100%|██████████| 346/346 [00:24<00:00, 14.29it/s]\n",
      "100%|██████████| 87/87 [00:04<00:00, 19.99it/s]\n",
      "Loss: 0.18170005083084106:   1%|          | 2/346 [00:00<00:24, 13.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:19 \t Accuracy:89.31933381607531\n",
      "EarlyStopping counter: 2 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.1949135810136795: 100%|██████████| 346/346 [00:23<00:00, 14.53it/s]  \n",
      "100%|██████████| 87/87 [00:04<00:00, 19.54it/s]\n",
      "Loss: 0.11915119737386703:   1%|          | 2/346 [00:00<00:25, 13.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:20 \t Accuracy:90.80376538740043\n",
      "Validation loss decreased (0.236457 --> 0.224152).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0917714536190033: 100%|██████████| 346/346 [00:23<00:00, 14.87it/s] \n",
      "100%|██████████| 87/87 [00:04<00:00, 19.70it/s]\n",
      "Loss: 0.26502206921577454:   1%|          | 2/346 [00:00<00:24, 13.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:21 \t Accuracy:88.848660391021\n",
      "EarlyStopping counter: 1 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.5337105393409729: 100%|██████████| 346/346 [00:23<00:00, 14.87it/s] \n",
      "100%|██████████| 87/87 [00:04<00:00, 19.58it/s]\n",
      "Loss: 0.2321438044309616:   1%|          | 2/346 [00:00<00:25, 13.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:22 \t Accuracy:91.09341057204924\n",
      "Validation loss decreased (0.224152 --> 0.222573).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.2796437442302704: 100%|██████████| 346/346 [00:23<00:00, 14.73it/s] \n",
      "100%|██████████| 87/87 [00:04<00:00, 19.53it/s]\n",
      "Loss: 0.3258102238178253:   1%|          | 2/346 [00:00<00:25, 13.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:23 \t Accuracy:91.20202751629255\n",
      "EarlyStopping counter: 1 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.021579839289188385: 100%|██████████| 346/346 [00:23<00:00, 14.63it/s]\n",
      "100%|██████████| 87/87 [00:04<00:00, 19.57it/s]\n",
      "Loss: 0.10655373334884644:   0%|          | 1/346 [00:00<00:42,  8.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:24 \t Accuracy:91.02099927588704\n",
      "EarlyStopping counter: 2 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.18538106977939606: 100%|██████████| 346/346 [00:23<00:00, 14.67it/s] \n",
      "100%|██████████| 87/87 [00:04<00:00, 19.67it/s]\n",
      "Loss: 0.13690230250358582:   1%|          | 2/346 [00:00<00:25, 13.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:25 \t Accuracy:90.91238233164374\n",
      "EarlyStopping counter: 3 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.10920313000679016: 100%|██████████| 346/346 [00:23<00:00, 14.57it/s] \n",
      "100%|██████████| 87/87 [00:04<00:00, 19.74it/s]\n",
      "Loss: 0.20582206547260284:   1%|          | 2/346 [00:00<00:25, 13.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:26 \t Accuracy:90.76755973931934\n",
      "EarlyStopping counter: 4 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.06214547157287598: 100%|██████████| 346/346 [00:23<00:00, 14.64it/s] \n",
      "100%|██████████| 87/87 [00:04<00:00, 20.00it/s]\n",
      "Loss: 0.20739884674549103:   1%|          | 2/346 [00:00<00:24, 13.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:27 \t Accuracy:91.52787834902244\n",
      "Validation loss decreased (0.222573 --> 0.218269).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.19360971450805664: 100%|██████████| 346/346 [00:23<00:00, 14.60it/s] \n",
      "100%|██████████| 87/87 [00:04<00:00, 19.96it/s]\n",
      "Loss: 0.09204600006341934:   1%|          | 2/346 [00:00<00:25, 13.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:28 \t Accuracy:90.80376538740043\n",
      "EarlyStopping counter: 1 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.15398919582366943: 100%|██████████| 346/346 [00:23<00:00, 14.61it/s] \n",
      "100%|██████████| 87/87 [00:04<00:00, 19.27it/s]\n",
      "Loss: 0.1832505315542221:   1%|          | 2/346 [00:00<00:25, 13.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:29 \t Accuracy:91.67270094134685\n",
      "EarlyStopping counter: 2 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.39062440395355225: 100%|██████████| 346/346 [00:23<00:00, 14.56it/s] \n",
      "100%|██████████| 87/87 [00:04<00:00, 19.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:30 \t Accuracy:88.26937002172339\n",
      "EarlyStopping counter: 3 out of 5\n",
      "====================\n",
      "Training finished !!\n",
      "====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "trainer.perform_training(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9d35616e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-13T02:00:55.687139Z",
     "start_time": "2021-04-13T00:50:41.911Z"
    }
   },
   "outputs": [],
   "source": [
    "# trainer.evaluate(0, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6fccdf19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total execution training time:  847.6523497104645\n"
     ]
    }
   ],
   "source": [
    "end_time = time.time()\n",
    "print('Total execution training time: ', end_time-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8235da90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436d68aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f5285a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
