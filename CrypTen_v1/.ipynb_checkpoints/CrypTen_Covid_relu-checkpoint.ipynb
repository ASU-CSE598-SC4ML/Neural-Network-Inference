{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d50f2dd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:root:test\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.DEBUG)\n",
    "logging.debug(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27450142",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:module 'torchvision.models.mobilenet' has no attribute 'ConvBNReLU'\n",
      "INFO:root:==================\n",
      "INFO:root:DistributedCommunicator with rank 0\n",
      "INFO:root:==================\n",
      "INFO:root:Added key: store_based_barrier_key:1 to store for rank: 0\n",
      "INFO:root:Added key: store_based_barrier_key:2 to store for rank: 0\n",
      "INFO:root:Added key: store_based_barrier_key:3 to store for rank: 0\n",
      "INFO:root:World size = 1\n"
     ]
    }
   ],
   "source": [
    "import crypten\n",
    "import torch\n",
    "\n",
    "crypten.init()\n",
    "torch.set_num_threads(1)\n",
    "\n",
    "#ignore warnings\n",
    "import warnings; \n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b19ae94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.autograd as autograd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.utils.data as data\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import itertools\n",
    "\n",
    "from torchvision import transforms, datasets, models\n",
    "\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4607c0f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MiniONN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        pass\n",
    "        \n",
    "    def forward(self, x):\n",
    "        h = F.relu(x)\n",
    "        \n",
    "        return h\n",
    "        \n",
    "model_ft = MiniONN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4821ac04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_n_params(model):\n",
    "    pp=0\n",
    "    for p in list(model.parameters()):\n",
    "        nn=1\n",
    "        for s in list(p.size()):\n",
    "            nn=nn*s\n",
    "        pp+=nn\n",
    "    return pp\n",
    "\n",
    "get_n_params(model_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "99d0a490",
   "metadata": {},
   "outputs": [],
   "source": [
    "ALICE = 0\n",
    "BOB = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "31472ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import crypten.mpc as mpc\n",
    "import crypten.communicator as comm\n",
    "\n",
    "transform = transforms.Compose([\n",
    "            lambda x: Image.open(x).convert('RGB'),\n",
    "            transforms.Resize((8, 8)),\n",
    "            transforms.ToTensor(),\n",
    "            lambda x: torch.rand(1,1,32,32)\n",
    "#             transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "        ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d4415306",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:==================\n",
      "INFO:root:DistributedCommunicator with rank 0\n",
      "INFO:root:==================\n",
      "INFO:root:==================\n",
      "INFO:root:DistributedCommunicator with rank 1\n",
      "INFO:root:==================\n",
      "INFO:root:Added key: store_based_barrier_key:1 to store for rank: 0\n",
      "INFO:root:Added key: store_based_barrier_key:1 to store for rank: 1\n",
      "INFO:root:Added key: store_based_barrier_key:2 to store for rank: 0\n",
      "INFO:root:Added key: store_based_barrier_key:2 to store for rank: 1\n",
      "INFO:root:Added key: store_based_barrier_key:3 to store for rank: 0\n",
      "INFO:root:Added key: store_based_barrier_key:3 to store for rank: 1\n",
      "INFO:root:Added key: store_based_barrier_key:4 to store for rank: 0\n",
      "INFO:root:World size = 2\n",
      "INFO:root:Added key: store_based_barrier_key:4 to store for rank: 1\n",
      "INFO:root:World size = 2\n",
      "DEBUG:PIL.PngImagePlugin:STREAM b'IHDR' 16 13\n",
      "DEBUG:PIL.PngImagePlugin:STREAM b'tIME' 41 7\n",
      "DEBUG:PIL.PngImagePlugin:b'tIME' 41 7 (unknown)\n",
      "DEBUG:PIL.PngImagePlugin:STREAM b'IHDR' 16 13\n",
      "DEBUG:PIL.PngImagePlugin:STREAM b'IDAT' 60 8192\n",
      "DEBUG:PIL.PngImagePlugin:STREAM b'tIME' 41 7\n",
      "DEBUG:PIL.PngImagePlugin:b'tIME' 41 7 (unknown)\n",
      "DEBUG:PIL.PngImagePlugin:STREAM b'IDAT' 60 8192\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: Time:  0.140519380569458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:====Communication Stats====\n",
      "INFO:root:Rounds: 9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Bytes : 237568\n",
      "INFO:root:Comm time: 0.00632622699959029\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13433456420898438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:====Communication Stats====\n",
      "INFO:root:Rounds: 9\n",
      "INFO:root:Bytes : 237568\n",
      "INFO:root:Comm time: 0.002575649999016605\n",
      "INFO:root:==================\n",
      "INFO:root:DistributedCommunicator with rank 0\n",
      "INFO:root:==================\n",
      "INFO:root:Added key: store_based_barrier_key:1 to store for rank: 0\n",
      "INFO:root:Added key: store_based_barrier_key:2 to store for rank: 0\n",
      "INFO:root:Added key: store_based_barrier_key:3 to store for rank: 0\n",
      "INFO:root:World size = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 15.8 ms, sys: 18.5 ms, total: 34.3 ms\n",
      "Wall time: 399 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "\n",
    "# labels = torch.load('/tmp/bob_test_labels.pth').long()\n",
    "# count = 100 # For illustration purposes, we'll use only 100 samples for classification\n",
    "\n",
    "@mpc.run_multiprocess(world_size=2)\n",
    "def encrypt_model_and_data():\n",
    "    crypten.comm.get().set_verbosity(True)\n",
    "    # Load pre-trained model to Alice\n",
    "    model = crypten.load('../training/models/relu.pt', dummy_model=model_ft, src=ALICE)\n",
    "    \n",
    "    # Encrypt model from Alice \n",
    "    dummy_input = torch.empty((1, 1, 32, 32))\n",
    "    private_model = crypten.nn.from_pytorch(model.double(), dummy_input.double())\n",
    "\n",
    "    private_model.encrypt(src=ALICE)\n",
    "    \n",
    "    # Load data to Bob\n",
    "    data_enc = crypten.cryptensor(transform('../training/dataset/COVID/COVID-1.png').unsqueeze(0), src=BOB)\n",
    "\n",
    "    # Classify the encrypted data\n",
    "    private_model.eval()\n",
    "    start = time.time()\n",
    "    \n",
    "\n",
    "    output_enc = private_model(data_enc)\n",
    "    end = time.time()\n",
    "\n",
    "\n",
    "\n",
    "    # Compute the accuracy\n",
    "    print('Time: ', end-start)\n",
    "    crypten.print_communication_stats()\n",
    "    \n",
    "encrypt_model_and_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e04626a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(crypten.print_communication_stats())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e1819d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
